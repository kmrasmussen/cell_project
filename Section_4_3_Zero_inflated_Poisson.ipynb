{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Section 4.3 - Zero-inflated Poisson.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmrasmussen/cell_project/blob/main/Section_4_3_Zero_inflated_Poisson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buzretRVnJYV"
      },
      "source": [
        "# ZIP\n",
        "\n",
        "Standard vanilla VAE but with zero-inflated Poisson likelihood"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnG9WdZ3d9yX",
        "outputId": "eee066a7-09d0-405e-c602-d69e0992566c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "!pip install pyro-ppl"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyro-ppl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/1b/946ff38dd8675b8fa114444df0940db078eb42e5354df46645a9e9467085/pyro_ppl-1.5.0-py3-none-any.whl (604kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (4.41.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.6.0+cu101)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/81/957ae78e6398460a7230b0eb9b8f1cb954c5e913e868e48d89324c68cec7/pyro_api-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->pyro-ppl) (0.16.0)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUe0SSgYnJYW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import pyro"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf1QWZkNnf00",
        "outputId": "2049d418-278d-411e-ae74-d6dbcfd0fc38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U43uktD5n3TG"
      },
      "source": [
        "class CellDataset(Dataset):\n",
        "  def __init__(self, numpy_matrix, batch_labels):\n",
        "    self.X = torch.from_numpy(numpy_matrix)\n",
        "    self.n_genes = self.X.shape[1]\n",
        "    self.batch_labels = batch_labels.reshape(-1).astype(np.float32)\n",
        "    self.batch_label_max = int(np.max(self.batch_labels))\n",
        "\n",
        "    # Library sizes for each cell, mean and variance across cells\n",
        "    self.cell_log_library_sizes = torch.sum(self.X, dim = 1)\n",
        "    self.log_library_sizes_mean = self.cell_log_library_sizes.mean().item()\n",
        "    self.log_library_sizes_var = self.cell_log_library_sizes.var().item()\n",
        "    print('Library sizes mean', self.log_library_sizes_mean, 'var', self.log_library_sizes_var)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {'x': self.X[idx], 'library_size': self.cell_log_library_sizes[idx], 'batch_number': self.batch_labels[idx]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkIiolUfnJYg"
      },
      "source": [
        "X = np.load('/content/gdrive/My Drive/uni_archive/cell/immune_control_subsampled_alone.npy')\n",
        "y = np.zeros(X.shape[0])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHu2Aid1nJYx",
        "outputId": "fddf22b6-61dc-4320-e223-ad1fbf8acb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset = CellDataset(X, y)\n",
        "minibatch_size = 32\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [7000, 3000, 3019])\n",
        "train_loader = DataLoader(train_set, batch_size=minibatch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=minibatch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=minibatch_size, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Library sizes mean 545.81494140625 var 369664.1875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPm4rZHjP-I8",
        "outputId": "9bc3df9e-e869-4d1c-b335-6b867db305fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUlTBKHtnJY8"
      },
      "source": [
        "class ZIP_VAE_FORSOEG2(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        # encoder part\n",
        "        self.mu_1 = nn.Linear(x_dim, h_dim1)\n",
        "        torch.nn.init.xavier_uniform_(self.mu_1.weight)\n",
        "        self.mu_2 = nn.Linear(h_dim1, h_dim2)\n",
        "        torch.nn.init.xavier_uniform_(self.mu_2.weight)\n",
        "        self.mu_3 = nn.Linear(h_dim1, z_dim)\n",
        "        torch.nn.init.xavier_uniform_(self.mu_3.weight)\n",
        "\n",
        "        self.var_1 = nn.Linear(x_dim, h_dim1)\n",
        "        torch.nn.init.xavier_uniform_(self.var_1.weight)\n",
        "        self.var_2 = nn.Linear(h_dim1, h_dim2)\n",
        "        torch.nn.init.xavier_uniform_(self.var_2.weight)\n",
        "        self.var_3 = nn.Linear(h_dim1, z_dim)\n",
        "        torch.nn.init.xavier_uniform_(self.var_3.weight)\n",
        "\n",
        "        # decoder part\n",
        "        self.dec_1 = nn.Linear(z_dim, h_dim2)\n",
        "        #self.dec_2 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.dec_3 = nn.Linear(h_dim2, x_dim)\n",
        "\n",
        "        self.dec_dropout_1 = nn.Linear(z_dim, h_dim2)\n",
        "        #self.dec_2 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.dec_dropout_3 = nn.Linear(h_dim2, x_dim)\n",
        "        \n",
        "    def encoder(self, x):\n",
        "        mu = F.relu(self.mu_1(x))\n",
        "        #mu = F.relu(self.mu_2(mu))\n",
        "        mu = self.mu_3(mu)\n",
        "\n",
        "        log_var = F.relu(self.var_1(x))\n",
        "        #log_var = F.relu(self.var_2(log_var))\n",
        "        log_var = self.var_3(log_var)\n",
        "        return mu, log_var # mu, log_var\n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # return z sample\n",
        "        \n",
        "    def decoder(self, z):\n",
        "        h = F.relu(self.dec_1(z))\n",
        "        #h = F.relu(self.dec_2(h))\n",
        "        h = self.dec_3(h)\n",
        "        #h = F.sigmoid(h)\n",
        "\n",
        "        dropout = F.relu(self.dec_dropout_1(z))\n",
        "        dropout = self.dec_dropout_3(dropout)\n",
        "        return h, dropout\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encoder(x)\n",
        "        z = self.sampling(mu, log_var)\n",
        "        log_lambdas, dropout = self.decoder(z)\n",
        "        return log_lambdas, dropout, mu, log_var"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXFjmTUwnJZB"
      },
      "source": [
        "def train(model, dataloader, optimizer, loss_function, kld_beta):\n",
        "    model.train()\n",
        "    \n",
        "    total_train_loss = 0.\n",
        "    running_loss = 0.\n",
        "    running_recons_loss = 0.\n",
        "    running_kld_loss = 0.\n",
        "    for batch_idx, data in enumerate(dataloader):\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x = data['x']\n",
        "        if torch.cuda.is_available():\n",
        "          x = x.cuda()\n",
        "        log_lambdas, dropout, mu, log_var = model(x)\n",
        "        loss, recons_loss, kld_loss = loss_function(log_lambdas, dropout, mu, log_var, x, kld_beta)\n",
        "        #print('loss', loss)\n",
        "\n",
        "        if loss > 1e10:\n",
        "          print('Might want to skip this optimizing step')\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        running_loss += loss.item()\n",
        "        running_recons_loss += recons_loss.item()\n",
        "        running_kld_loss += kld_loss.item()\n",
        "        #if batch_idx % 100 == 99:\n",
        "        #    print('Running loss', np.round(running_loss / (100. * minibatch_size)))\n",
        "        #    running_loss = 0.\n",
        "    return total_train_loss / len(dataloader.dataset), running_recons_loss / len(dataloader.dataset), running_kld_loss / len(dataloader.dataset)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W4RayVDnJZH"
      },
      "source": [
        "def validate(model, dataloader, optimizer, loss_function, kld_beta):\n",
        "    model.eval()\n",
        "    \n",
        "    total_val_loss = 0.\n",
        "    running_loss = 0.\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(dataloader):\n",
        "\n",
        "            x = data['x']\n",
        "            if torch.cuda.is_available():\n",
        "              x = x.cuda()\n",
        "            log_lambdas, dropout, mu, log_var = model(x)\n",
        "            loss, recons_loss, kld_loss = loss_function(log_lambdas, dropout, mu, log_var, x, kld_beta)\n",
        "            \n",
        "            total_val_loss += loss.item()\n",
        "            running_loss += loss.item()\n",
        "            #if batch_idx % 100 == 99:\n",
        "            #    print('Running loss', np.round(running_loss / (100. * minibatch_size)))\n",
        "            #    running_loss = 0.\n",
        "    return total_val_loss / len(dataloader.dataset)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekru9D9NnJZU"
      },
      "source": [
        "def poisson_loss_function_pyro(recons_x, mu, log_var, x, kld_beta):\n",
        "    log_lambdas = recons_x\n",
        "    log_lambdas = torch.clamp(input = log_lambdas, min=-9, max = 9.)\n",
        "    lambdas = torch.exp(log_lambdas) #+ 1.\n",
        "    poisson_dist = pyro.distributions.Poisson(lambdas) #.to_event(1)\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    log_probs = poisson_dist.log_prob(x)\n",
        "    poisson_likelihood = log_probs.sum()\n",
        "    elbo = None\n",
        "    if kld_beta == 0.:\n",
        "        elbo = poisson_likelihood\n",
        "    else:\n",
        "        elbo = poisson_likelihood - kld_beta * KLD\n",
        "    loss = -elbo\n",
        "    if torch.isnan(loss) or torch.isinf(loss):\n",
        "        print('log lambdas', log_lambdas, torch.isnan(log_lambdas).sum())\n",
        "        print('lambdas', lambdas, torch.isnan(log_lambdas).sum())\n",
        "        print('log probs', log_probs, torch.isnan(log_lambdas).sum())\n",
        "        raise Exception('NaN loss')\n",
        "    return loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mins_Rovnl9u"
      },
      "source": [
        "def zip_loss_function_pyro(log_lambdas, dropout, mu, log_var, x, kld_beta):\n",
        "    log_lambdas = torch.clamp(input = log_lambdas, min=-9., max = 9.)\n",
        "    dropout = torch.clamp(input = dropout, min=-10., max = 9.)\n",
        "    lambdas = torch.exp(log_lambdas) #+ 1.\n",
        "    dropout = torch.sigmoid(dropout)\n",
        "    poisson_dist = pyro.distributions.zero_inflated.ZeroInflatedPoisson(gate = dropout, rate = lambdas) #pyro.distributions.Poisson(lambdas) #.to_event(1)\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    log_probs = poisson_dist.log_prob(x)\n",
        "    poisson_likelihood = log_probs.sum()\n",
        "    elbo = None\n",
        "    if kld_beta == 0.:\n",
        "        elbo = poisson_likelihood\n",
        "    else:\n",
        "        #print('KLD', KLD)\n",
        "        elbo = poisson_likelihood - kld_beta * KLD\n",
        "    loss = -elbo\n",
        "    if torch.isnan(loss) or torch.isinf(loss):\n",
        "        print('log lambdas', log_lambdas, torch.isnan(log_lambdas).sum())\n",
        "        print('lambdas', lambdas, torch.isnan(log_lambdas).sum())\n",
        "        print('log probs', log_probs, torch.isnan(log_lambdas).sum())\n",
        "        raise Exception('NaN loss')\n",
        "    return loss, poisson_likelihood, kld_beta * KLD"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv_ihNUhnJZZ",
        "outputId": "e8720f98-a68d-4876-ae02-8c935b19f955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# build model\n",
        "vae = ZIP_VAE_FORSOEG2(x_dim=dataset.n_genes, h_dim1= 512, h_dim2=256, z_dim=20)\n",
        "if torch.cuda.is_available():\n",
        "    vae.cuda()\n",
        "optimizer = optim.Adam(vae.parameters(), lr=0.00001)\n",
        "\n",
        "n_epochs = 500\n",
        "train_history = []\n",
        "kld_history = []\n",
        "recons_history = []\n",
        "val_history = []\n",
        "ready_to_activate_kld = False\n",
        "activate_kld_after = 10\n",
        "ready_to_activate_aggresive = False\n",
        "for epoch in range(n_epochs):\n",
        "    print('Epoch', epoch)\n",
        "    kld_beta = 0.\n",
        "    if ready_to_activate_kld:\n",
        "        kld_beta = min(1.0, 0.1 * (epoch - activate_kld_after))\n",
        "    print('kld beta:', kld_beta)\n",
        "    train_loss, recons_loss, kld_loss = train(vae, train_loader, optimizer, zip_loss_function_pyro, kld_beta)\n",
        "    print('train loss', train_loss, 'recons', recons_loss, 'kld', kld_loss)\n",
        "    if train_loss < 1500. and ready_to_activate_kld == False:\n",
        "      activate_kld_after = epoch\n",
        "      #print('Ready for kld')\n",
        "      ready_to_activate_kld = True\n",
        "    if train_loss < 1000. and ready_to_activate_aggresive == False:\n",
        "      ready_to_activate_aggresive = True\n",
        "      print('Increasing learning rate')\n",
        "      for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = 0.0001\n",
        "    val_loss = validate(vae, val_loader, optimizer, zip_loss_function_pyro, kld_beta)\n",
        "    print('validation loss', val_loss)\n",
        "    train_history.append(train_loss)\n",
        "    val_history.append(val_loss)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "kld beta: 0.0\n",
            "train loss 67817.63591517857 recons -67817.63591517857 kld nan\n",
            "validation loss 13856.698408854167\n",
            "Epoch 1\n",
            "kld beta: 0.0\n",
            "train loss 7432.974815290178 recons -7432.974815290178 kld nan\n",
            "validation loss 5171.749893229166\n",
            "Epoch 2\n",
            "kld beta: 0.0\n",
            "train loss 4960.512890066964 recons -4960.512890066964 kld nan\n",
            "validation loss 3997.0402330729166\n",
            "Epoch 3\n",
            "kld beta: 0.0\n",
            "train loss 4489.183912388393 recons -4489.183912388393 kld nan\n",
            "validation loss 3842.5500625\n",
            "Epoch 4\n",
            "kld beta: 0.0\n",
            "train loss 4036.422543526786 recons -4036.422543526786 kld nan\n",
            "validation loss 3321.73938671875\n",
            "Epoch 5\n",
            "kld beta: 0.0\n",
            "train loss 3849.189459263393 recons -3849.189459263393 kld nan\n",
            "validation loss 3211.8419322916666\n",
            "Epoch 6\n",
            "kld beta: 0.0\n",
            "train loss 3686.355719029018 recons -3686.355719029018 kld nan\n",
            "validation loss 2989.883349609375\n",
            "Epoch 7\n",
            "kld beta: 0.0\n",
            "train loss 3528.5116183035716 recons -3528.5116183035716 kld nan\n",
            "validation loss 2840.3751243489583\n",
            "Epoch 8\n",
            "kld beta: 0.0\n",
            "train loss 3490.0493175223214 recons -3490.0493175223214 kld nan\n",
            "validation loss 2744.1754524739586\n",
            "Epoch 9\n",
            "kld beta: 0.0\n",
            "train loss 3436.647982421875 recons -3436.647982421875 kld nan\n",
            "validation loss 2641.697650390625\n",
            "Epoch 10\n",
            "kld beta: 0.0\n",
            "train loss 3393.754515904018 recons -3393.754515904018 kld nan\n",
            "validation loss 2729.271806640625\n",
            "Epoch 11\n",
            "kld beta: 0.0\n",
            "train loss 3308.9038175223213 recons -3308.9038175223213 kld nan\n",
            "validation loss 2572.7531705729166\n",
            "Epoch 12\n",
            "kld beta: 0.0\n",
            "train loss 3327.9698214285713 recons -3327.9698214285713 kld nan\n",
            "validation loss 2632.9304290364585\n",
            "Epoch 13\n",
            "kld beta: 0.0\n",
            "train loss 3192.926923828125 recons -3192.926923828125 kld nan\n",
            "validation loss 2563.393443359375\n",
            "Epoch 14\n",
            "kld beta: 0.0\n",
            "train loss 3210.1300697544643 recons -3210.1300697544643 kld nan\n",
            "validation loss 2531.314320963542\n",
            "Epoch 15\n",
            "kld beta: 0.0\n",
            "train loss 3207.5841919642858 recons -3207.5841919642858 kld nan\n",
            "validation loss 2513.8368912760416\n",
            "Epoch 16\n",
            "kld beta: 0.0\n",
            "train loss 3116.33366796875 recons -3116.33366796875 kld nan\n",
            "validation loss 2418.3956158854166\n",
            "Epoch 17\n",
            "kld beta: 0.0\n",
            "train loss 3028.212749441964 recons -3028.212749441964 kld 0.0\n",
            "validation loss 2391.308118489583\n",
            "Epoch 18\n",
            "kld beta: 0.0\n",
            "train loss 3017.2245524553573 recons -3017.2245524553573 kld 0.0\n",
            "validation loss 2466.0581145833335\n",
            "Epoch 19\n",
            "kld beta: 0.0\n",
            "train loss 2962.235181361607 recons -2962.235181361607 kld 0.0\n",
            "validation loss 2462.3592415364583\n",
            "Epoch 20\n",
            "kld beta: 0.0\n",
            "train loss 3027.0764031808035 recons -3027.0764031808035 kld 0.0\n",
            "validation loss 2410.086393229167\n",
            "Epoch 21\n",
            "kld beta: 0.0\n",
            "train loss 2946.625056361607 recons -2946.625056361607 kld nan\n",
            "validation loss 2309.881216145833\n",
            "Epoch 22\n",
            "kld beta: 0.0\n",
            "train loss 2931.691437220982 recons -2931.691437220982 kld nan\n",
            "validation loss 2332.58245703125\n",
            "Epoch 23\n",
            "kld beta: 0.0\n",
            "train loss 2921.8380108816964 recons -2921.8380108816964 kld nan\n",
            "validation loss 2329.3793919270834\n",
            "Epoch 24\n",
            "kld beta: 0.0\n",
            "train loss 2894.494787109375 recons -2894.494787109375 kld nan\n",
            "validation loss 2344.7786080729165\n",
            "Epoch 25\n",
            "kld beta: 0.0\n",
            "train loss 2880.7540496651786 recons -2880.7540496651786 kld 0.0\n",
            "validation loss 2277.4718092447915\n",
            "Epoch 26\n",
            "kld beta: 0.0\n",
            "train loss 2878.819158761161 recons -2878.819158761161 kld 0.0\n",
            "validation loss 2280.3224482421874\n",
            "Epoch 27\n",
            "kld beta: 0.0\n",
            "train loss 2858.753080496652 recons -2858.753080496652 kld 0.0\n",
            "validation loss 2318.4527708333335\n",
            "Epoch 28\n",
            "kld beta: 0.0\n",
            "train loss 2875.713793108259 recons -2875.713793108259 kld 0.0\n",
            "validation loss 2173.2312760416667\n",
            "Epoch 29\n",
            "kld beta: 0.0\n",
            "train loss 2779.7448189174106 recons -2779.7448189174106 kld 0.0\n",
            "validation loss 2216.3161575520835\n",
            "Epoch 30\n",
            "kld beta: 0.0\n",
            "train loss 2809.026202706473 recons -2809.026202706473 kld 0.0\n",
            "validation loss 2251.106090169271\n",
            "Epoch 31\n",
            "kld beta: 0.0\n",
            "train loss 2787.59628125 recons -2787.59628125 kld 0.0\n",
            "validation loss 2174.819376953125\n",
            "Epoch 32\n",
            "kld beta: 0.0\n",
            "train loss 2759.5692151227677 recons -2759.5692151227677 kld 0.0\n",
            "validation loss 2207.739271484375\n",
            "Epoch 33\n",
            "kld beta: 0.0\n",
            "train loss 2670.3705528738838 recons -2670.3705528738838 kld 0.0\n",
            "validation loss 2232.4897180989583\n",
            "Epoch 34\n",
            "kld beta: 0.0\n",
            "train loss 2784.675251953125 recons -2784.675251953125 kld 0.0\n",
            "validation loss 2170.5761608072917\n",
            "Epoch 35\n",
            "kld beta: 0.0\n",
            "train loss 2684.680825055804 recons -2684.680825055804 kld 0.0\n",
            "validation loss 2199.713375\n",
            "Epoch 36\n",
            "kld beta: 0.0\n",
            "train loss 2673.0624913504466 recons -2673.0624913504466 kld 0.0\n",
            "validation loss 2110.4377154947915\n",
            "Epoch 37\n",
            "kld beta: 0.0\n",
            "train loss 2689.550020926339 recons -2689.550020926339 kld 0.0\n",
            "validation loss 2127.2080859375\n",
            "Epoch 38\n",
            "kld beta: 0.0\n",
            "train loss 2707.3067338169644 recons -2707.3067338169644 kld 0.0\n",
            "validation loss 2139.621733723958\n",
            "Epoch 39\n",
            "kld beta: 0.0\n",
            "train loss 2692.744223772321 recons -2692.744223772321 kld 0.0\n",
            "validation loss 2126.0046438802083\n",
            "Epoch 40\n",
            "kld beta: 0.0\n",
            "train loss 2587.1077198660714 recons -2587.1077198660714 kld 0.0\n",
            "validation loss 2194.21484765625\n",
            "Epoch 41\n",
            "kld beta: 0.0\n",
            "train loss 2622.9416999162945 recons -2622.9416999162945 kld 0.0\n",
            "validation loss 2118.1972936197917\n",
            "Epoch 42\n",
            "kld beta: 0.0\n",
            "train loss 2617.507521484375 recons -2617.507521484375 kld 0.0\n",
            "validation loss 2246.5280045572918\n",
            "Epoch 43\n",
            "kld beta: 0.0\n",
            "train loss 2576.63409375 recons -2576.63409375 kld 0.0\n",
            "validation loss 2117.6457955729165\n",
            "Epoch 44\n",
            "kld beta: 0.0\n",
            "train loss 2489.197840401786 recons -2489.197840401786 kld 0.0\n",
            "validation loss 2101.8415423177084\n",
            "Epoch 45\n",
            "kld beta: 0.0\n",
            "train loss 2518.959164620536 recons -2518.959164620536 kld 0.0\n",
            "validation loss 1942.22876953125\n",
            "Epoch 46\n",
            "kld beta: 0.0\n",
            "train loss 1929.9115913783482 recons -1929.9115913783482 kld 0.0\n",
            "validation loss 1190.4190218098959\n",
            "Epoch 47\n",
            "kld beta: 0.0\n",
            "train loss 981.7485179966518 recons -981.7485179966518 kld 0.0\n",
            "Increasing learning rate\n",
            "validation loss 983.5161529947917\n",
            "Epoch 48\n",
            "kld beta: 0.1\n",
            "train loss 859.5749790736608 recons -807.1928150111607 kld 52.38215917532784\n",
            "validation loss 855.9819833984375\n",
            "Epoch 49\n",
            "kld beta: 0.2\n",
            "train loss 739.5794782366071 recons -704.8568678850446 kld 34.722608651297435\n",
            "validation loss 850.7060732421875\n",
            "Epoch 50\n",
            "kld beta: 0.30000000000000004\n",
            "Might want to skip this optimizing step\n",
            "train loss 18808381.543169364 recons -809.7853235212053 kld 18807572.06030209\n",
            "validation loss 824.0079563802084\n",
            "Epoch 51\n",
            "kld beta: 0.4\n",
            "train loss 1370.3016085379463 recons -672.9592601841517 kld 697.3423177664621\n",
            "validation loss 813.7609765625\n",
            "Epoch 52\n",
            "kld beta: 0.5\n",
            "train loss 833.3630270647321 recons -734.2199794921875 kld 99.14305167933873\n",
            "validation loss 811.18139453125\n",
            "Epoch 53\n",
            "kld beta: 0.6000000000000001\n",
            "Might want to skip this optimizing step\n",
            "train loss 368340313.9424007 recons -656.6248147321429 kld 368339644.1048438\n",
            "validation loss 806.0730491536458\n",
            "Epoch 54\n",
            "kld beta: 0.7000000000000001\n",
            "train loss 673.0983529575893 recons -609.7844820033482 kld 63.31387168666295\n",
            "validation loss 822.585455078125\n",
            "Epoch 55\n",
            "kld beta: 0.8\n",
            "train loss 660.7608244977679 recons -600.1375221819196 kld 60.623305297851566\n",
            "validation loss 819.1685107421876\n",
            "Epoch 56\n",
            "kld beta: 0.9\n",
            "train loss 677.3732438616072 recons -611.4506153738839 kld 65.92262875802176\n",
            "validation loss 830.19036328125\n",
            "Epoch 57\n",
            "kld beta: 1.0\n",
            "train loss 663.5550930524554 recons -600.665613420759 kld 62.88947910853795\n",
            "validation loss 824.2468131510417\n",
            "Epoch 58\n",
            "kld beta: 1.0\n",
            "train loss 675.246103515625 recons -615.095326171875 kld 60.15077793666295\n",
            "validation loss 814.208783203125\n",
            "Epoch 59\n",
            "kld beta: 1.0\n",
            "train loss 657.2124328962053 recons -598.6818119419643 kld 58.53062040492466\n",
            "validation loss 825.5096595052083\n",
            "Epoch 60\n",
            "kld beta: 1.0\n",
            "train loss 650.3504345703125 recons -594.223867327009 kld 56.12656656319754\n",
            "validation loss 763.4449869791666\n",
            "Epoch 61\n",
            "kld beta: 1.0\n",
            "train loss 652.1525619419643 recons -597.811171875 kld 54.34139071219308\n",
            "validation loss 786.9520211588542\n",
            "Epoch 62\n",
            "kld beta: 1.0\n",
            "train loss 645.5333045479911 recons -592.0453138950893 kld 53.48799020821708\n",
            "validation loss 777.3965465494791\n",
            "Epoch 63\n",
            "kld beta: 1.0\n",
            "train loss 662.6712331194196 recons -581.7889796316964 kld 80.88225276402065\n",
            "validation loss 768.902201171875\n",
            "Epoch 64\n",
            "kld beta: 1.0\n",
            "train loss 623.9789055524553 recons -572.911185407366 kld 51.06772043282645\n",
            "validation loss 846.7617682291667\n",
            "Epoch 65\n",
            "kld beta: 1.0\n",
            "train loss 618.3358151506696 recons -569.9338653738839 kld 48.40195027378627\n",
            "validation loss 791.0755927734375\n",
            "Epoch 66\n",
            "kld beta: 1.0\n",
            "train loss 622.8834175502233 recons -573.0878232421875 kld 49.795594177246095\n",
            "validation loss 775.96428125\n",
            "Epoch 67\n",
            "kld beta: 1.0\n",
            "train loss 622.1795623604911 recons -574.824293108259 kld 47.35526916503906\n",
            "validation loss 833.1260979817708\n",
            "Epoch 68\n",
            "kld beta: 1.0\n",
            "train loss 620.2773881138393 recons -573.9176480189732 kld 46.35974136788504\n",
            "validation loss 767.2931070963542\n",
            "Epoch 69\n",
            "kld beta: 1.0\n",
            "train loss 643.2585789620535 recons -594.4645407366071 kld 48.794038635253905\n",
            "validation loss 783.1403434244792\n",
            "Epoch 70\n",
            "kld beta: 1.0\n",
            "train loss 625.0090108816964 recons -576.7074539620536 kld 48.301558576311386\n",
            "validation loss 767.2489544270833\n",
            "Epoch 71\n",
            "kld beta: 1.0\n",
            "train loss 616.4109354073661 recons -569.4276576450893 kld 46.983279139927454\n",
            "validation loss 824.1351337890625\n",
            "Epoch 72\n",
            "kld beta: 1.0\n",
            "train loss 613.57115625 recons -567.0764501953125 kld 46.49470655168806\n",
            "validation loss 740.3442356770834\n",
            "Epoch 73\n",
            "kld beta: 1.0\n",
            "train loss 605.7352883649554 recons -561.0601262555804 kld 44.67516346086774\n",
            "validation loss 809.9730397135417\n",
            "Epoch 74\n",
            "kld beta: 1.0\n",
            "train loss 599.9705392020089 recons -556.8939613560268 kld 43.076576956612726\n",
            "validation loss 756.3888059895834\n",
            "Epoch 75\n",
            "kld beta: 1.0\n",
            "train loss 601.4704773995536 recons -557.8119393136161 kld 43.65853812953404\n",
            "validation loss 755.4573098958333\n",
            "Epoch 76\n",
            "kld beta: 1.0\n",
            "train loss 594.1783073381696 recons -551.754931640625 kld 42.423376604352676\n",
            "validation loss 762.6584208984375\n",
            "Epoch 77\n",
            "kld beta: 1.0\n",
            "train loss 591.0184660993303 recons -549.9696337890625 kld 41.04883296421596\n",
            "validation loss 784.6790992838542\n",
            "Epoch 78\n",
            "kld beta: 1.0\n",
            "train loss 628.2086079799108 recons -582.6001870814732 kld 45.60841947719029\n",
            "validation loss 870.3375\n",
            "Epoch 79\n",
            "kld beta: 1.0\n",
            "train loss 605.3238285435268 recons -560.209058454241 kld 45.11476990618024\n",
            "validation loss 734.0187991536459\n",
            "Epoch 80\n",
            "kld beta: 1.0\n",
            "train loss 598.8825964006696 recons -555.8055446428572 kld 43.07705224609375\n",
            "validation loss 767.2174332682291\n",
            "Epoch 81\n",
            "kld beta: 1.0\n",
            "train loss 598.610638671875 recons -552.8401216517857 kld 45.770514500209266\n",
            "validation loss 771.4761383463542\n",
            "Epoch 82\n",
            "kld beta: 1.0\n",
            "train loss 590.943611328125 recons -548.3490267857143 kld 42.59458424595424\n",
            "validation loss 749.8835595703125\n",
            "Epoch 83\n",
            "kld beta: 1.0\n",
            "train loss 598.7232174944196 recons -556.5493777901786 kld 42.17383911132813\n",
            "validation loss 773.00289453125\n",
            "Epoch 84\n",
            "kld beta: 1.0\n",
            "train loss 597.9604736328125 recons -554.9370929129465 kld 43.023377467564174\n",
            "validation loss 767.757166015625\n",
            "Epoch 85\n",
            "kld beta: 1.0\n",
            "train loss 588.4234670758929 recons -546.9448120814732 kld 41.47865462820871\n",
            "validation loss 724.6283639322917\n",
            "Epoch 86\n",
            "kld beta: 1.0\n",
            "train loss 593.0880717075893 recons -552.6481858258928 kld 40.43988589041574\n",
            "validation loss 735.7084547526042\n",
            "Epoch 87\n",
            "kld beta: 1.0\n",
            "train loss 617.5540016741071 recons -573.3725101841518 kld 44.181491455078124\n",
            "validation loss 683.4333372395834\n",
            "Epoch 88\n",
            "kld beta: 1.0\n",
            "train loss 615.7457915736608 recons -570.4120958426339 kld 45.333697501046316\n",
            "validation loss 722.3170003255208\n",
            "Epoch 89\n",
            "kld beta: 1.0\n",
            "train loss 707.2270541294642 recons -651.041291015625 kld 56.185758605957034\n",
            "validation loss 707.5389440104167\n",
            "Epoch 90\n",
            "kld beta: 1.0\n",
            "train loss 590.7848491908483 recons -544.8476964285715 kld 45.93715302385603\n",
            "validation loss 755.4826962890625\n",
            "Epoch 91\n",
            "kld beta: 1.0\n",
            "train loss 593.108398297991 recons -549.0621223493304 kld 44.04627684674944\n",
            "validation loss 702.6185169270833\n",
            "Epoch 92\n",
            "kld beta: 1.0\n",
            "train loss 579.8355159040178 recons -539.8025961216517 kld 40.03291934640067\n",
            "validation loss 744.6835319010416\n",
            "Epoch 93\n",
            "kld beta: 1.0\n",
            "train loss 582.0191057477679 recons -542.4923996930803 kld 39.52670640345982\n",
            "validation loss 690.8575631510416\n",
            "Epoch 94\n",
            "kld beta: 1.0\n",
            "train loss 574.4680959821428 recons -535.4459619140625 kld 39.0221340070452\n",
            "validation loss 724.1597503255208\n",
            "Epoch 95\n",
            "kld beta: 1.0\n",
            "train loss 570.5437399553572 recons -531.716126953125 kld 38.827612513950896\n",
            "validation loss 703.5923255208334\n",
            "Epoch 96\n",
            "kld beta: 1.0\n",
            "train loss 578.5809195033482 recons -539.6833316127232 kld 38.89758545793806\n",
            "validation loss 713.6587705078125\n",
            "Epoch 97\n",
            "kld beta: 1.0\n",
            "train loss 577.3918517020089 recons -538.8402822265625 kld 38.55156889125279\n",
            "validation loss 728.1887060546875\n",
            "Epoch 98\n",
            "kld beta: 1.0\n",
            "train loss 577.3553600725446 recons -539.233185407366 kld 38.122175197056364\n",
            "validation loss 687.3032877604167\n",
            "Epoch 99\n",
            "kld beta: 1.0\n",
            "train loss 581.2624535435268 recons -542.2987290736608 kld 38.96372419084821\n",
            "validation loss 688.8331966145834\n",
            "Epoch 100\n",
            "kld beta: 1.0\n",
            "train loss 604.7857650669642 recons -558.8505263671875 kld 45.93523885672433\n",
            "validation loss 707.3632692057291\n",
            "Epoch 101\n",
            "kld beta: 1.0\n",
            "train loss 576.7192349330358 recons -535.2757356305804 kld 41.44349936349052\n",
            "validation loss 696.7800514322917\n",
            "Epoch 102\n",
            "kld beta: 1.0\n",
            "train loss 567.206068359375 recons -528.2630552455357 kld 38.943013654436385\n",
            "validation loss 705.6751383463542\n",
            "Epoch 103\n",
            "kld beta: 1.0\n",
            "train loss 568.5650344587053 recons -530.7696736886161 kld 37.795360604422434\n",
            "validation loss 687.2733004557292\n",
            "Epoch 104\n",
            "kld beta: 1.0\n",
            "train loss 598.7226268136161 recons -543.4858038504465 kld 55.23682210867746\n",
            "validation loss 683.080390625\n",
            "Epoch 105\n",
            "kld beta: 1.0\n",
            "train loss 44036.879593331476 recons -589.4566833147321 kld 43447.42410579137\n",
            "validation loss 686.0534283854166\n",
            "Epoch 106\n",
            "kld beta: 1.0\n",
            "train loss 578.8107424665178 recons -539.761970703125 kld 39.04877178083147\n",
            "validation loss 689.5170764973958\n",
            "Epoch 107\n",
            "kld beta: 1.0\n",
            "train loss 589.6276007254464 recons -548.219482282366 kld 41.40811888776507\n",
            "validation loss 684.5067203776042\n",
            "Epoch 108\n",
            "kld beta: 1.0\n",
            "train loss 570.639306640625 recons -530.9045637555804 kld 39.73474385288783\n",
            "validation loss 668.1144934895833\n",
            "Epoch 109\n",
            "kld beta: 1.0\n",
            "train loss 565.3243042689733 recons -527.6569038783482 kld 37.6674011492048\n",
            "validation loss 688.908720703125\n",
            "Epoch 110\n",
            "kld beta: 1.0\n",
            "train loss 562.6841651785714 recons -525.0973021763393 kld 37.58686287144252\n",
            "validation loss 698.78133203125\n",
            "Epoch 111\n",
            "kld beta: 1.0\n",
            "train loss 624.1596022600446 recons -584.5535207868304 kld 39.606083286830355\n",
            "validation loss 682.3702255859375\n",
            "Epoch 112\n",
            "kld beta: 1.0\n",
            "train loss 1938.5891803850448 recons -547.3779299665179 kld 1391.2111998291016\n",
            "validation loss 670.5273421223958\n",
            "Epoch 113\n",
            "kld beta: 1.0\n",
            "train loss 568.6287961774553 recons -531.0463087332589 kld 37.582486162458146\n",
            "validation loss 678.5699752604166\n",
            "Epoch 114\n",
            "kld beta: 1.0\n",
            "train loss 561.8260837053572 recons -525.208783203125 kld 36.617300310407366\n",
            "validation loss 726.4878714192708\n",
            "Epoch 115\n",
            "kld beta: 1.0\n",
            "train loss 581.8157357700893 recons -540.5017894810268 kld 41.31394763183594\n",
            "validation loss 685.701947265625\n",
            "Epoch 116\n",
            "kld beta: 1.0\n",
            "train loss 566.3855601283482 recons -526.2462663225447 kld 40.13929351806641\n",
            "validation loss 692.8588430989583\n",
            "Epoch 117\n",
            "kld beta: 1.0\n",
            "train loss 564.9374422433036 recons -527.2364305245536 kld 37.7010105242048\n",
            "validation loss 709.6587581380209\n",
            "Epoch 118\n",
            "kld beta: 1.0\n",
            "train loss 576.2556004464286 recons -533.7152154017857 kld 42.54038417271205\n",
            "validation loss 716.5258509114583\n",
            "Epoch 119\n",
            "kld beta: 1.0\n",
            "train loss 724.7495599888393 recons -575.7415087890626 kld 149.00805041503907\n",
            "validation loss 682.1104560546875\n",
            "Epoch 120\n",
            "kld beta: 1.0\n",
            "train loss 568.1972935267858 recons -529.7262476283482 kld 38.4710451398577\n",
            "validation loss 684.239810546875\n",
            "Epoch 121\n",
            "kld beta: 1.0\n",
            "train loss 558.0624222935268 recons -520.1736148158482 kld 37.88880668422154\n",
            "validation loss 684.705150390625\n",
            "Epoch 122\n",
            "kld beta: 1.0\n",
            "train loss 612.4355366908483 recons -564.0755712890625 kld 48.359965035574774\n",
            "validation loss 684.3554690755209\n",
            "Epoch 123\n",
            "kld beta: 1.0\n",
            "train loss 556.7550456194197 recons -516.1694998604911 kld 40.58554666573661\n",
            "validation loss 667.9120960286458\n",
            "Epoch 124\n",
            "kld beta: 1.0\n",
            "train loss 556.5303189174107 recons -517.3832794363839 kld 39.14703956821987\n",
            "validation loss 687.8846399739583\n",
            "Epoch 125\n",
            "kld beta: 1.0\n",
            "train loss 562.9269496372768 recons -521.8964988839285 kld 41.03045096261161\n",
            "validation loss 655.4712880859375\n",
            "Epoch 126\n",
            "kld beta: 1.0\n",
            "train loss 552.7782472098214 recons -515.2838138950893 kld 37.494433445521764\n",
            "validation loss 662.1983743489583\n",
            "Epoch 127\n",
            "kld beta: 1.0\n",
            "train loss 560.4950046037947 recons -521.8894546595982 kld 38.60554950823103\n",
            "validation loss 661.7817718098959\n",
            "Epoch 128\n",
            "kld beta: 1.0\n",
            "train loss 552.1467272600446 recons -515.4293551897322 kld 36.71737216622489\n",
            "validation loss 658.7522027994792\n",
            "Epoch 129\n",
            "kld beta: 1.0\n",
            "train loss 576.9643133370536 recons -519.885802734375 kld 57.0785105242048\n",
            "validation loss 659.9144427083334\n",
            "Epoch 130\n",
            "kld beta: 1.0\n",
            "train loss 552.2731488560268 recons -517.1857585100446 kld 35.08738924734933\n",
            "validation loss 691.4863492838541\n",
            "Epoch 131\n",
            "kld beta: 1.0\n",
            "train loss 555.7523394252232 recons -519.0422575334821 kld 36.710082188197546\n",
            "validation loss 652.6898284505208\n",
            "Epoch 132\n",
            "kld beta: 1.0\n",
            "train loss 551.1323377511161 recons -514.6599381975446 kld 36.47240040806361\n",
            "validation loss 663.6034671223958\n",
            "Epoch 133\n",
            "kld beta: 1.0\n",
            "train loss 547.9119186662947 recons -512.6863450055804 kld 35.225572771344865\n",
            "validation loss 721.7336676432292\n",
            "Epoch 134\n",
            "kld beta: 1.0\n",
            "train loss 548.7983201729911 recons -512.4558518415179 kld 36.342468549455916\n",
            "validation loss 665.1225374348959\n",
            "Epoch 135\n",
            "kld beta: 1.0\n",
            "train loss 545.7529441964285 recons -510.4698304966518 kld 35.28311476353237\n",
            "validation loss 675.2190520833333\n",
            "Epoch 136\n",
            "kld beta: 1.0\n",
            "train loss 549.6042349330357 recons -514.7509741908482 kld 34.85325962611607\n",
            "validation loss 715.3568089192709\n",
            "Epoch 137\n",
            "kld beta: 1.0\n",
            "train loss 558.1867278180804 recons -521.4487506975446 kld 36.737977826799664\n",
            "validation loss 694.4092659505209\n",
            "Epoch 138\n",
            "kld beta: 1.0\n",
            "train loss 548.9828133370536 recons -512.8220948660714 kld 36.16071914236886\n",
            "validation loss 642.9196481119792\n",
            "Epoch 139\n",
            "kld beta: 1.0\n",
            "train loss 546.2659714006696 recons -510.6794702845982 kld 35.58650255475725\n",
            "validation loss 661.3178001302083\n",
            "Epoch 140\n",
            "kld beta: 1.0\n",
            "train loss 551.296787109375 recons -512.6603560267857 kld 38.63643222481864\n",
            "validation loss 682.5850654296875\n",
            "Epoch 141\n",
            "kld beta: 1.0\n",
            "train loss 547.1337935267857 recons -510.8660765904018 kld 36.26771665736607\n",
            "validation loss 651.5292744140625\n",
            "Epoch 142\n",
            "kld beta: 1.0\n",
            "train loss 547.1765119977679 recons -511.4432416294643 kld 35.73327069963727\n",
            "validation loss 670.0354781901042\n",
            "Epoch 143\n",
            "kld beta: 1.0\n",
            "train loss 544.5620234375 recons -508.73248046875 kld 35.82954238455636\n",
            "validation loss 651.0210393880209\n",
            "Epoch 144\n",
            "kld beta: 1.0\n",
            "train loss 546.9767476283482 recons -510.58209709821426 kld 36.39465101841518\n",
            "validation loss 657.7078990885417\n",
            "Epoch 145\n",
            "kld beta: 1.0\n",
            "train loss 541.2202437220982 recons -506.2025994698661 kld 35.01764382498605\n",
            "validation loss 671.3379182942708\n",
            "Epoch 146\n",
            "kld beta: 1.0\n",
            "train loss 542.7587513950892 recons -507.96688420758926 kld 34.79186678641183\n",
            "validation loss 643.2770130208334\n",
            "Epoch 147\n",
            "kld beta: 1.0\n",
            "train loss 890.189482421875 recons -523.1095185546875 kld 367.079951625279\n",
            "validation loss 674.535908203125\n",
            "Epoch 148\n",
            "kld beta: 1.0\n",
            "train loss 542.6470811941964 recons -507.1037220982143 kld 35.543358511788504\n",
            "validation loss 668.7284775390625\n",
            "Epoch 149\n",
            "kld beta: 1.0\n",
            "train loss 542.3482667410715 recons -507.8772017299107 kld 34.47106543840681\n",
            "validation loss 666.6271852213541\n",
            "Epoch 150\n",
            "kld beta: 1.0\n",
            "train loss 565.1702866908482 recons -521.8160258091518 kld 43.35426146589007\n",
            "validation loss 660.2539752604167\n",
            "Epoch 151\n",
            "kld beta: 1.0\n",
            "train loss 542.4430768694197 recons -505.9450436662946 kld 36.49803405761719\n",
            "validation loss 654.2702805989584\n",
            "Epoch 152\n",
            "kld beta: 1.0\n",
            "train loss 540.6760698939732 recons -505.4751166294643 kld 35.20095322963169\n",
            "validation loss 641.439521484375\n",
            "Epoch 153\n",
            "kld beta: 1.0\n",
            "train loss 537.3116005859375 recons -503.0195609654018 kld 34.29203945486886\n",
            "validation loss 642.5839938151041\n",
            "Epoch 154\n",
            "kld beta: 1.0\n",
            "train loss 539.7818826729911 recons -505.0014891183036 kld 34.78039392089844\n",
            "validation loss 641.225955078125\n",
            "Epoch 155\n",
            "kld beta: 1.0\n",
            "train loss 544.2180770089286 recons -509.7132583705357 kld 34.5048193359375\n",
            "validation loss 642.668025390625\n",
            "Epoch 156\n",
            "kld beta: 1.0\n",
            "train loss 542.4150902622767 recons -507.5014185267857 kld 34.91367299107143\n",
            "validation loss 652.750185546875\n",
            "Epoch 157\n",
            "kld beta: 1.0\n",
            "train loss 535.8048909040178 recons -498.8688500279018 kld 36.936040640694756\n",
            "validation loss 644.1821692708334\n",
            "Epoch 158\n",
            "kld beta: 1.0\n",
            "train loss 830.5553399832589 recons -514.7431953125 kld 315.81214870779854\n",
            "validation loss 652.3090680338541\n",
            "Epoch 159\n",
            "kld beta: 1.0\n",
            "train loss 544.0520182756696 recons -508.7226714564732 kld 35.329349417550226\n",
            "validation loss 653.7476468098959\n",
            "Epoch 160\n",
            "kld beta: 1.0\n",
            "train loss 540.2458383091517 recons -503.8096149553571 kld 36.436223440987725\n",
            "validation loss 646.1681627604166\n",
            "Epoch 161\n",
            "kld beta: 1.0\n",
            "train loss 539.5513226841518 recons -502.4660414341518 kld 37.0852837437221\n",
            "validation loss 672.1708479817709\n",
            "Epoch 162\n",
            "kld beta: 1.0\n",
            "train loss 539.024054827009 recons -502.668544921875 kld 36.35550959995815\n",
            "validation loss 644.6814059244791\n",
            "Epoch 163\n",
            "kld beta: 1.0\n",
            "train loss 542.8183212890625 recons -507.3370542689732 kld 35.48126668875558\n",
            "validation loss 655.6929088541667\n",
            "Epoch 164\n",
            "kld beta: 1.0\n",
            "train loss 535.9486393694197 recons -500.537689453125 kld 35.41094958496094\n",
            "validation loss 657.4217327473958\n",
            "Epoch 165\n",
            "kld beta: 1.0\n",
            "train loss 534.7975267857142 recons -500.2341820591518 kld 34.563345232282366\n",
            "validation loss 649.2811422526041\n",
            "Epoch 166\n",
            "kld beta: 1.0\n",
            "train loss 538.0078526785715 recons -503.2833716517857 kld 34.72448095703125\n",
            "validation loss 651.45064453125\n",
            "Epoch 167\n",
            "kld beta: 1.0\n",
            "train loss 538.8530046037946 recons -503.293822265625 kld 35.55918341936384\n",
            "validation loss 654.2396608072917\n",
            "Epoch 168\n",
            "kld beta: 1.0\n",
            "train loss 537.4645732421875 recons -499.0189086216518 kld 38.445667471749445\n",
            "validation loss 646.623224609375\n",
            "Epoch 169\n",
            "kld beta: 1.0\n",
            "train loss 554.6015239955357 recons -515.8823069196428 kld 38.719216413225446\n",
            "validation loss 648.3325963541666\n",
            "Epoch 170\n",
            "kld beta: 1.0\n",
            "train loss 535.3570954241071 recons -496.66011565290177 kld 38.69697774832589\n",
            "validation loss 651.9219371744791\n",
            "Epoch 171\n",
            "kld beta: 1.0\n",
            "train loss 533.0149829799108 recons -497.19200223214284 kld 35.82298072160993\n",
            "validation loss 635.730453125\n",
            "Epoch 172\n",
            "kld beta: 1.0\n",
            "train loss 528.9501282087053 recons -494.5541820591518 kld 34.39594605364118\n",
            "validation loss 666.8924189453126\n",
            "Epoch 173\n",
            "kld beta: 1.0\n",
            "train loss 551.4482018694197 recons -513.9416810825893 kld 37.506518589564735\n",
            "validation loss 630.3335725911459\n",
            "Epoch 174\n",
            "kld beta: 1.0\n",
            "train loss 554.4099547991071 recons -519.4920700334822 kld 34.91788546316964\n",
            "validation loss 641.6411617838542\n",
            "Epoch 175\n",
            "kld beta: 1.0\n",
            "train loss 11898.73406389509 recons -507.35247865513395 kld 11391.38198967634\n",
            "validation loss 650.523544921875\n",
            "Epoch 176\n",
            "kld beta: 1.0\n",
            "train loss 533.9139527064732 recons -497.00640234375 kld 36.90754884556362\n",
            "validation loss 636.5664140625\n",
            "Epoch 177\n",
            "kld beta: 1.0\n",
            "train loss 536.06193359375 recons -500.0382144252232 kld 36.02371869768415\n",
            "validation loss 632.4227275390625\n",
            "Epoch 178\n",
            "kld beta: 1.0\n",
            "train loss 531.3721487165178 recons -496.6088279854911 kld 34.76332039969308\n",
            "validation loss 639.1554723307291\n",
            "Epoch 179\n",
            "kld beta: 1.0\n",
            "train loss 526.5598671875 recons -491.8027202845982 kld 34.757146981375556\n",
            "validation loss 629.5233675130208\n",
            "Epoch 180\n",
            "kld beta: 1.0\n",
            "train loss 564.2063695591518 recons -516.270255859375 kld 47.93611456298828\n",
            "validation loss 637.3125081380208\n",
            "Epoch 181\n",
            "kld beta: 1.0\n",
            "train loss 524.4286575055803 recons -489.9719408482143 kld 34.45671613420759\n",
            "validation loss 676.0953785807292\n",
            "Epoch 182\n",
            "kld beta: 1.0\n",
            "train loss 528.2829426618304 recons -494.205611328125 kld 34.0773304007394\n",
            "validation loss 655.5692027994792\n",
            "Epoch 183\n",
            "kld beta: 1.0\n",
            "train loss 552.7073713727679 recons -512.9206047712054 kld 39.78676611328125\n",
            "validation loss 637.7710751953125\n",
            "Epoch 184\n",
            "kld beta: 1.0\n",
            "train loss 526.7805041852679 recons -491.0933150111607 kld 35.687188991001676\n",
            "validation loss 630.9775361328125\n",
            "Epoch 185\n",
            "kld beta: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-191aabaa8817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mkld_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mactivate_kld_after\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kld beta:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkld_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkld_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_loss_function_pyro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkld_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recons'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kld'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkld_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1500.\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mready_to_activate_kld\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-c75338bc9235>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, loss_function, kld_beta)\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Might want to skip this optimizing step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56BJ6eyfnJZi",
        "outputId": "a43130da-2e26-439b-d96c-d23e02305050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss = validate(vae, test_loader, optimizer, zip_loss_function_pyro, kld_beta = 1.0)\n",
        "print('Test loss', test_loss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss 655.4706533102849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxUReD9zsNyu",
        "outputId": "6568d8c4-8354-46c5-907f-7d4b50a498a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "vae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ZIP_VAE_FORSOEG2(\n",
              "  (mu_1): Linear(in_features=4000, out_features=512, bias=True)\n",
              "  (mu_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (mu_3): Linear(in_features=512, out_features=20, bias=True)\n",
              "  (var_1): Linear(in_features=4000, out_features=512, bias=True)\n",
              "  (var_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (var_3): Linear(in_features=512, out_features=20, bias=True)\n",
              "  (dec_1): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (dec_3): Linear(in_features=256, out_features=4000, bias=True)\n",
              "  (dec_dropout_1): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (dec_dropout_3): Linear(in_features=256, out_features=4000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIpMLhJ6j6p_"
      },
      "source": [
        "train_history = np.array(train_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8M7zntLkAYw"
      },
      "source": [
        "train_history[165] = train_history[164]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVtP5VI3nJZ4",
        "outputId": "9db0fc38-b471-4c9e-b2ba-a014fbd3ae27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(np.arange(2,len(train_history)), train_history[2:], label='train')\n",
        "plt.plot(np.arange(2,len(train_history)), val_history[2:], label='val')\n",
        "plt.axhline(test_loss, c='red', label='test ' + str(int(test_loss)))\n",
        "plt.title('Loss ZIP VAE on IMMUNE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('/content/gdrive/My Drive/Colab Notebooks/Colab Cell Experiments/plots/zip_vae_forsoeg2_aggressive_a_history.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLyPtofMgDug"
      },
      "source": [
        "#torch.save(vae, '/content/gdrive/My Drive/Colab Notebooks/Colab Cell Experiments/outputs/zip_vae_forsoeg2_aggresive_a.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO18SAW5nJaB"
      },
      "source": [
        "# Plot it all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSn1mOVFnJaC"
      },
      "source": [
        "X_tensor = torch.tensor(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhaD8jP1TSAK",
        "outputId": "0636cc49-0362-40d8-bc04-9c73ee6af739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DCxkA1YU98R"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  X_tensor = X_tensor.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJAgt8mVnJaL"
      },
      "source": [
        "X_encoded = vae.encoder(X_tensor.float())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoOLQ89EnJaT"
      },
      "source": [
        "X_encoded_means = X_encoded[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClspdiYtVwry",
        "outputId": "4e904d15-d176-4a4f-a982-5b19165b5756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "X_encoded_means.cpu()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8895,  0.2600,  0.5370,  ...,  1.5225,  1.8514,  0.9220],\n",
              "        [ 0.0519, -1.2115, -0.0133,  ..., -2.4756, -2.0484,  0.8484],\n",
              "        [ 0.5229,  0.2378,  1.3798,  ..., -2.0123, -0.8380,  3.6613],\n",
              "        ...,\n",
              "        [-0.1771, -1.4606, -0.6591,  ..., -0.2644, -1.4738, -1.1531],\n",
              "        [ 0.9850,  0.7420,  0.5417,  ...,  0.4935,  1.3731,  0.0760],\n",
              "        [ 2.2770, -0.1258,  0.4462,  ...,  0.7765, -0.4128,  0.9020]],\n",
              "       grad_fn=<CopyBackwards>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF2GKJgoVzTM",
        "outputId": "d5f6167d-db83-4b13-c07f-c3e11c3a98db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "X_encoded_means"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8895,  0.2600,  0.5370,  ...,  1.5225,  1.8514,  0.9220],\n",
              "        [ 0.0519, -1.2115, -0.0133,  ..., -2.4756, -2.0484,  0.8484],\n",
              "        [ 0.5229,  0.2378,  1.3798,  ..., -2.0123, -0.8380,  3.6613],\n",
              "        ...,\n",
              "        [-0.1771, -1.4606, -0.6591,  ..., -0.2644, -1.4738, -1.1531],\n",
              "        [ 0.9850,  0.7420,  0.5417,  ...,  0.4935,  1.3731,  0.0760],\n",
              "        [ 2.2770, -0.1258,  0.4462,  ...,  0.7765, -0.4128,  0.9020]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBM55rqqnJaX"
      },
      "source": [
        "import umap\n",
        "reducer = umap.UMAP()\n",
        "X_encoded_umap = reducer.fit_transform(X_encoded_means.detach().cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLQSSB54nJac",
        "outputId": "29705ce4-95a1-4fa5-f0bf-7f98c0d57073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.title('ZIP VAE + UMAP on IMMUNE')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.scatter(X_encoded_umap[:,0], X_encoded_umap[:,1])\n",
        "plt.savefig('/content/gdrive/My Drive/Colab Notebooks/Colab Cell Experiments/plots/zip_vae_forsoeg2_aggresive_a_umap.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR_z3qmanJak"
      },
      "source": [
        "## Generate cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyVdl0QynJak"
      },
      "source": [
        "Z_samples = torch.randn(1000, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rH0uTdWnJaq"
      },
      "source": [
        "Z_samples_umap_transformed = reducer.transform(Z_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3S_G7JknJav"
      },
      "source": [
        "absolute_zero = torch.zeros(1, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9RkgGV6nJa1",
        "outputId": "0892782f-adc2-4556-dd72-f7f04f771e7c"
      },
      "source": [
        "plt.scatter(X_encoded_umap[:,0], X_encoded_umap[:,1])\n",
        "plt.scatter(Z_samples_umap_transformed[:,0], Z_samples_umap_transformed[:,1])\n",
        "plt.scatter(absolute_zero[:,0], absolute_zero[:,1], c='red')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x13f8630a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3GCrWqDnJa6"
      },
      "source": [
        "generated_decoded = None\n",
        "with torch.no_grad():\n",
        "    generated_decoded = vae.decoder(Z_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd4958NgnJa_",
        "outputId": "fd75176a-c668-461b-9f2b-ac32aee20242"
      },
      "source": [
        "generated_decoded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 4000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7GpRdSHnJbD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}